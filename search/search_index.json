{"config":{"lang":["en"],"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"embarcadero-mind-machine \u00b6 embarcadero mind machine is an extensible framework for running Github bot flocks. embarcadero mind machine uses the mind machine framework to provide the user with a simple set of building blocks for building bot flocks: a Keymaker, a Shepherd, and a Sheep. The philosophy is to help users get started quickly, and build on simple behaviors to create complex, rich bot behaviors. See embarcadero-mind-machine in action ! All the shields \u00b6 Links \u00b6 embarcadero mind machine (emm) links: emm source code on Github: https://github.com/rainbow-mind-machine/embarcadero-mind-machine emm documentation: https://pages.charlesreid1.com/embarcadero-mind-machine rainbow mind machine organization on Github: https://github.com/rainbow-mind-machine releases: emm releases on Github: https://github.com/rainbow-mind-machine/embarcadero-mind-machine/releases emm on pypi: https://pypi.org/project/embarcaderomindmachine/ emm on dockerhub: https://hub.docker.com/r/rainbowmindmachine/embarcaderomindmachine/ Pages \u00b6 About the Mind Machine Framework - general information about the mind machine framework (how does it work? what does it look like?) About Embarcadero Mind Machine - about this library (what is it? what does it do?) Installing - installation instructions (how do I install bmm?) Quick Start - quick start instructions for getting started with embarcadero mind machine - run your first bot flock! Documentation for components implemented in embarcadero mind machine: emm.GithubKeymaker emm.GithubShepherd emm.GithubSheep Developer Notes \u00b6 See Developer Notes for info about the workflow for uploading changes to pypi and dockerhub. See Contributing for info about how to contribute to the project. Get In Touch \u00b6 Contact the author: embarcaderomindmachine@charlesreid1.com","title":"Home"},{"location":"#embarcadero-mind-machine","text":"embarcadero mind machine is an extensible framework for running Github bot flocks. embarcadero mind machine uses the mind machine framework to provide the user with a simple set of building blocks for building bot flocks: a Keymaker, a Shepherd, and a Sheep. The philosophy is to help users get started quickly, and build on simple behaviors to create complex, rich bot behaviors. See embarcadero-mind-machine in action !","title":"embarcadero-mind-machine"},{"location":"#all-the-shields","text":"","title":"All the shields"},{"location":"#links","text":"embarcadero mind machine (emm) links: emm source code on Github: https://github.com/rainbow-mind-machine/embarcadero-mind-machine emm documentation: https://pages.charlesreid1.com/embarcadero-mind-machine rainbow mind machine organization on Github: https://github.com/rainbow-mind-machine releases: emm releases on Github: https://github.com/rainbow-mind-machine/embarcadero-mind-machine/releases emm on pypi: https://pypi.org/project/embarcaderomindmachine/ emm on dockerhub: https://hub.docker.com/r/rainbowmindmachine/embarcaderomindmachine/","title":"Links"},{"location":"#pages","text":"About the Mind Machine Framework - general information about the mind machine framework (how does it work? what does it look like?) About Embarcadero Mind Machine - about this library (what is it? what does it do?) Installing - installation instructions (how do I install bmm?) Quick Start - quick start instructions for getting started with embarcadero mind machine - run your first bot flock! Documentation for components implemented in embarcadero mind machine: emm.GithubKeymaker emm.GithubShepherd emm.GithubSheep","title":"Pages"},{"location":"#developer-notes","text":"See Developer Notes for info about the workflow for uploading changes to pypi and dockerhub. See Contributing for info about how to contribute to the project.","title":"Developer Notes"},{"location":"#get-in-touch","text":"Contact the author: embarcaderomindmachine@charlesreid1.com","title":"Get In Touch"},{"location":"about/","text":"About embarcadero mind machine \u00b6 embarcadero mind machine (emm) is a library for running Github bot flocks. It is owned by the rainbow-mind-machine organization on Github. Like all mind machines, embarcadero mind machine is simple and extensible. How is embarcadero mind machine simple? \u00b6 The mind machine framework revolves around providing a few simple components for building bot flocks: Keymaker classes Shepherd classes Sheep classes But it gets even simpler than that: boring-mind-machine provides a GithubKeymaker class , so that embarcadero mind machine can focus exclusively on Shepherd and Sheep classes. That's pretty simple! What does embarcadero mind machine extend or do? \u00b6 embarcadero mind machine is extensible to keep bots from becoming boring. There are a limited number of components to extend (2), these two components have a simple and clear function call order, and embarcadero mind machine tries to use sensible defaults. That means we start out with bots that \"just work\" and we can incrementally improve, extend, override, or redefine behaviors to make them increasingly complex, while still abstracting away messy details. How is embarcadero mind machine POOP-y? \u00b6 The embarcadero mind machine library makes good use of concepts in Python Object Oriented Programming, or POOP. The embarcadero mind machine library uses inheritance, because the entire library is built on base classes provided by boring mind machine. Additionally, the whole way embarcadero mind machine works is to provide a set of useful classes, but also make it easy for users to write their own classes. Everything is about classes.","title":"About emm"},{"location":"about/#about-embarcadero-mind-machine","text":"embarcadero mind machine (emm) is a library for running Github bot flocks. It is owned by the rainbow-mind-machine organization on Github. Like all mind machines, embarcadero mind machine is simple and extensible.","title":"About embarcadero mind machine"},{"location":"about/#how-is-embarcadero-mind-machine-simple","text":"The mind machine framework revolves around providing a few simple components for building bot flocks: Keymaker classes Shepherd classes Sheep classes But it gets even simpler than that: boring-mind-machine provides a GithubKeymaker class , so that embarcadero mind machine can focus exclusively on Shepherd and Sheep classes. That's pretty simple!","title":"How is embarcadero mind machine simple?"},{"location":"about/#what-does-embarcadero-mind-machine-extend-or-do","text":"embarcadero mind machine is extensible to keep bots from becoming boring. There are a limited number of components to extend (2), these two components have a simple and clear function call order, and embarcadero mind machine tries to use sensible defaults. That means we start out with bots that \"just work\" and we can incrementally improve, extend, override, or redefine behaviors to make them increasingly complex, while still abstracting away messy details.","title":"What does embarcadero mind machine extend or do?"},{"location":"about/#how-is-embarcadero-mind-machine-poop-y","text":"The embarcadero mind machine library makes good use of concepts in Python Object Oriented Programming, or POOP. The embarcadero mind machine library uses inheritance, because the entire library is built on base classes provided by boring mind machine. Additionally, the whole way embarcadero mind machine works is to provide a set of useful classes, but also make it easy for users to write their own classes. Everything is about classes.","title":"How is embarcadero mind machine POOP-y?"},{"location":"bmm_keymaker_github/","text":"Github Keymaker \u00b6 See examples/github/ . An example of creating a Github OAuth keymaker. This page gives an example of creating a Github OAuth Keymaker using the boring mind machine library. (Full Github bot functionality requires the embarcadero mind machine library .) Creating a Github App \u00b6 The brief summary of what we cover here: We need to create an application (something that will consume the API endpoints), and we need to grant the application access to at least one Github account. Set Up API and Create App \u00b6 To create an OAuth app as a user, see these detailed instructions from Github. When you create your OAuth app, the one crucial piece of information is the callback URL. This is where the magic token is sent once the user logs in with their Github account. The Github Keymaker runs a server on localhost port 8000, so the callback URL for your OAuth application should be set to http://localhost:8000 . Getting App Credentials \u00b6 Once you have created your application, the application's description page will contain the client ID and client secret needed to use this application to run mind machine bots using Github. Setting Github Credentials \u00b6 In the end you should have a pair of API keys (a client ID and a client secret), which you will pass to the keymaker using one of the three methods provided (via a dictionary, a JSON file, or environment variables). To run the Github Keymaker example, you need to pass the API keys to the keymaker using one of three methods: Using a dictionary Using a JSON file Using environment variables Environment Variables Example \u00b6 To use the environment variables option, you can run the Github Keymaker example program in examples/github/ like this: $ CLIENT_ID=\"...\" \\ CLIENT_SECRET=\"...\" \\ python github_auth.py Example Code \u00b6 github_auth.py : import boringmindmachine as bmm import subprocess keydir = 'keys' gk = bmm . GithubKeymaker () gk . set_apikeys_env () # Make the Github key print ( \"Creating a dummy key...\" ) gk . make_a_key ( 'dummy' , 'dummy.json' , keydir ) print ( \"Success.\" ) # Clean up the key # (remove this bit to keep the key around) print ( \"Cleaning up...\" ) subprocess . call ([ 'rm' , '-rf' , keydir ]) print ( \"Done.\" )","title":"Github Keymaker"},{"location":"bmm_keymaker_github/#github-keymaker","text":"See examples/github/ . An example of creating a Github OAuth keymaker. This page gives an example of creating a Github OAuth Keymaker using the boring mind machine library. (Full Github bot functionality requires the embarcadero mind machine library .)","title":"Github Keymaker"},{"location":"bmm_keymaker_github/#creating-a-github-app","text":"The brief summary of what we cover here: We need to create an application (something that will consume the API endpoints), and we need to grant the application access to at least one Github account.","title":"Creating a Github App"},{"location":"bmm_keymaker_github/#set-up-api-and-create-app","text":"To create an OAuth app as a user, see these detailed instructions from Github. When you create your OAuth app, the one crucial piece of information is the callback URL. This is where the magic token is sent once the user logs in with their Github account. The Github Keymaker runs a server on localhost port 8000, so the callback URL for your OAuth application should be set to http://localhost:8000 .","title":"Set Up API and Create App"},{"location":"bmm_keymaker_github/#getting-app-credentials","text":"Once you have created your application, the application's description page will contain the client ID and client secret needed to use this application to run mind machine bots using Github.","title":"Getting App Credentials"},{"location":"bmm_keymaker_github/#setting-github-credentials","text":"In the end you should have a pair of API keys (a client ID and a client secret), which you will pass to the keymaker using one of the three methods provided (via a dictionary, a JSON file, or environment variables). To run the Github Keymaker example, you need to pass the API keys to the keymaker using one of three methods: Using a dictionary Using a JSON file Using environment variables","title":"Setting Github Credentials"},{"location":"bmm_keymaker_github/#environment-variables-example","text":"To use the environment variables option, you can run the Github Keymaker example program in examples/github/ like this: $ CLIENT_ID=\"...\" \\ CLIENT_SECRET=\"...\" \\ python github_auth.py","title":"Environment Variables Example"},{"location":"bmm_keymaker_github/#example-code","text":"github_auth.py : import boringmindmachine as bmm import subprocess keydir = 'keys' gk = bmm . GithubKeymaker () gk . set_apikeys_env () # Make the Github key print ( \"Creating a dummy key...\" ) gk . make_a_key ( 'dummy' , 'dummy.json' , keydir ) print ( \"Success.\" ) # Clean up the key # (remove this bit to keep the key around) print ( \"Cleaning up...\" ) subprocess . call ([ 'rm' , '-rf' , keydir ]) print ( \"Done.\" )","title":"Example Code"},{"location":"contributing/","text":"Contributing \u00b6 Ways to Contribute \u00b6 Some ways that you can contribute, in order of increasing involvement: Read the documentation ! If you find a problem or can't understand something, open an issue (see below). Use embarcadero mind machine! You can test it out and come up with new ideas and ways of using embarcadero mind machine. Open an issue in the embarcadero mind machine repository on Github. The issue can be a bug, a question, an idea, or anything else. Fork embarcadero mind machine on Github!","title":"Contributing"},{"location":"contributing/#contributing","text":"","title":"Contributing"},{"location":"contributing/#ways-to-contribute","text":"Some ways that you can contribute, in order of increasing involvement: Read the documentation ! If you find a problem or can't understand something, open an issue (see below). Use embarcadero mind machine! You can test it out and come up with new ideas and ways of using embarcadero mind machine. Open an issue in the embarcadero mind machine repository on Github. The issue can be a bug, a question, an idea, or anything else. Fork embarcadero mind machine on Github!","title":"Ways to Contribute"},{"location":"credits/","text":"Credits \u00b6 Most of the magic in embarcadero mind machine happens via the excellent PyGithub library. All of the artwork is original photography by the author and is available under the terms of the MIT License.","title":"Credits"},{"location":"credits/#credits","text":"Most of the magic in embarcadero mind machine happens via the excellent PyGithub library. All of the artwork is original photography by the author and is available under the terms of the MIT License.","title":"Credits"},{"location":"emm_github/","text":"Github App \u00b6 Common components: Client ID Client Secret Where to find them Summary \u00b6 What this page covers: How to create/set up your app What information you need from your app to run the keymaker Create Github App \u00b6 Create a Github application. There is only one thing you are required to set, which is the callback URL. Set the callback URL to http://localhost:8000 (no HTTPS!). Once you create your app, you should see a Client ID and a Client Secret near the top of the page. These two pieces of information are the API keys that the Keymaker needs to start the OAuth process. Get Client ID and Client Secret \u00b6 Get your application's Client ID and Client Secret. The eaiest way to set these for embarcadero mind machine is to use environment variables. You can set the CLIENT_ID and CLIENT_SECRET variables to their respective values when you run embarcadero mind machine scripts: $ CLIENT_ID=\"XXX\" CLIENT_SECRET=\"XXXXX\" \\ python my_github_flock.py The Keymaker can be configured to obtain the client API keys from these environment variables.","title":"Github Guide"},{"location":"emm_github/#github-app","text":"Common components: Client ID Client Secret Where to find them","title":"Github App"},{"location":"emm_github/#summary","text":"What this page covers: How to create/set up your app What information you need from your app to run the keymaker","title":"Summary"},{"location":"emm_github/#create-github-app","text":"Create a Github application. There is only one thing you are required to set, which is the callback URL. Set the callback URL to http://localhost:8000 (no HTTPS!). Once you create your app, you should see a Client ID and a Client Secret near the top of the page. These two pieces of information are the API keys that the Keymaker needs to start the OAuth process.","title":"Create Github App"},{"location":"emm_github/#get-client-id-and-client-secret","text":"Get your application's Client ID and Client Secret. The eaiest way to set these for embarcadero mind machine is to use environment variables. You can set the CLIENT_ID and CLIENT_SECRET variables to their respective values when you run embarcadero mind machine scripts: $ CLIENT_ID=\"XXX\" CLIENT_SECRET=\"XXXXX\" \\ python my_github_flock.py The Keymaker can be configured to obtain the client API keys from these environment variables.","title":"Get Client ID and Client Secret"},{"location":"emm_keymaker/","text":"Github Keymaker \u00b6 embarcadero mind machine defines a Keymaker object for authenticating with the Github API via OAuth. A Quick One-Bot Example \u00b6 Here is a quick demo to authenticate a bot account and create a JSON key: examples/quick_start/one_bot.py import embarcaderomindmachine as emm gk = emm.GithubKeymaker() gk.set_apikeys_env() gk.make_a_key('dummy','dummy.json','/tmp/keys') The Github Keymaker object is what walks you through the OAuth2 process. The gk.set_apikeys_env() method gets the application's consumer ID and consumer secret from environment variables ( CONSUMER_ID and CONSUMER_SECRET , respectively). The Keymaker also has methods to set the API keys from a JSON file or from a dictionary. Last, we run the make_a_key() method to actually generate the key. Note that this is not the normal workflow, we usually pass a list of items to the Keymaker and ask it to generate one key (i.e., authenticate one bot account) per item. In this case, we force the Keymaker to create a single key named \"dummy\" that will be stored in /tmp/keys/dummy.json . A Two-Bot Example \u00b6","title":"Github Keymaker"},{"location":"emm_keymaker/#github-keymaker","text":"embarcadero mind machine defines a Keymaker object for authenticating with the Github API via OAuth.","title":"Github Keymaker"},{"location":"emm_keymaker/#a-quick-one-bot-example","text":"Here is a quick demo to authenticate a bot account and create a JSON key: examples/quick_start/one_bot.py import embarcaderomindmachine as emm gk = emm.GithubKeymaker() gk.set_apikeys_env() gk.make_a_key('dummy','dummy.json','/tmp/keys') The Github Keymaker object is what walks you through the OAuth2 process. The gk.set_apikeys_env() method gets the application's consumer ID and consumer secret from environment variables ( CONSUMER_ID and CONSUMER_SECRET , respectively). The Keymaker also has methods to set the API keys from a JSON file or from a dictionary. Last, we run the make_a_key() method to actually generate the key. Note that this is not the normal workflow, we usually pass a list of items to the Keymaker and ask it to generate one key (i.e., authenticate one bot account) per item. In this case, we force the Keymaker to create a single key named \"dummy\" that will be stored in /tmp/keys/dummy.json .","title":"A Quick One-Bot Example"},{"location":"emm_keymaker/#a-two-bot-example","text":"","title":"A Two-Bot Example"},{"location":"emm_sheep/","text":"Sheep \u00b6 The sheep defined by embarcadero mind machine have a lot of flexibility, primarily because of how many endpoints the Github API has. Our first bot example was a blame bot: two bots going back and forth blaming each other for an issue by re-assigning the issue to the other bot. Other bot flock ideas: bot making commits in repos license bot that looks for license files be mroe generic about actions and what bots are doing not just \"license bot to check for a license\" that is the central action, which the bot defines how to do but we want to go deeper - a given bot type can do a given action type we want each bot to have a different \"take\" on the action, a different way of doing it embarcadero mind machine Sheep have basic functionality described by the Github API. Ideas: ping pong pair - simple ping pong on an issue (no, it's your problem. :reassign:) favestar bots to_fave = []; faved = [];","title":"Github Sheep"},{"location":"emm_sheep/#sheep","text":"The sheep defined by embarcadero mind machine have a lot of flexibility, primarily because of how many endpoints the Github API has. Our first bot example was a blame bot: two bots going back and forth blaming each other for an issue by re-assigning the issue to the other bot. Other bot flock ideas: bot making commits in repos license bot that looks for license files be mroe generic about actions and what bots are doing not just \"license bot to check for a license\" that is the central action, which the bot defines how to do but we want to go deeper - a given bot type can do a given action type we want each bot to have a different \"take\" on the action, a different way of doing it embarcadero mind machine Sheep have basic functionality described by the Github API. Ideas: ping pong pair - simple ping pong on an issue (no, it's your problem. :reassign:) favestar bots to_fave = []; faved = [];","title":"Sheep"},{"location":"emm_shepherd/","text":"Shepherd \u00b6 The Shepherd is the object that loads the set of keys and uses them to construct Sheep objects. Inheritance notes: - base class is in boring mind machine - boring shepherd base class calls the verify key and the create sheep method - virtual methods that must be implemente by us Derived Shepherds only need to define: - how to validate keys - how to add sheep to flock As described in boring mind machine, any mind machine that wants to use the boring shepherd base class should define two methods, each taking a key: validate the key create a Sheep from the key","title":"Github Shepherd"},{"location":"emm_shepherd/#shepherd","text":"The Shepherd is the object that loads the set of keys and uses them to construct Sheep objects. Inheritance notes: - base class is in boring mind machine - boring shepherd base class calls the verify key and the create sheep method - virtual methods that must be implemente by us Derived Shepherds only need to define: - how to validate keys - how to add sheep to flock As described in boring mind machine, any mind machine that wants to use the boring shepherd base class should define two methods, each taking a key: validate the key create a Sheep from the key","title":"Shepherd"},{"location":"future/","text":"Future Work and Ideas \u00b6 (TODO: add future work/ideas)","title":"Future Work and Ideas"},{"location":"future/#future-work-and-ideas","text":"(TODO: add future work/ideas)","title":"Future Work and Ideas"},{"location":"installing/","text":"Installing embarcadero mind machine \u00b6 To install embarcadero mind machine manually, use the normal setup.py procedure: git clone https://github.com/rainbow-mind-machine/embarcadero-mind-machine.git cd embarcadero-mind-machine python setup.py build python setup.py install To install embarcadero mind machine with pip: pip install embarcaderomindmachine Required Packages \u00b6 If you need a list of required packages, see requirements.txt . These packages will be installed using either of the above installation methods. What You Need to Run a Bot Flock \u00b6 You will need a few additional things before you can get a bot flock up and running with embarcadero mind machine. A Bot Idea \u00b6 You will need to decide on the behaviors you want the bot to have, so you know how to structure the bot repository, what data to include, and how to extend Sheep and Shepherd. You will be defining how the Sheep (one sheep = one bot) will populate their tweet queues. This may be a simple action (get an item from a list owned by the Sheep), or it may be a complicated one (make a URL request to get live data, query a database, call an API, etc.). See example_flocks/ . Bot Master Account \u00b6 It's good practice to create the OAuth application you'll be using to run your bot flock under a bot master account. Like your OAuth application, the bot master account can be used to run as many bot flocks as you would like, so you don't need to make it flock-specific. This account is also (obviously) not itself a bot, so you can use your personal twitter account as the bot master account. Bot Accounts \u00b6 embarcadero mind machine handles everything but the creation of bot accounts. You must already have created a user account for each bot. No customization of the bot accounts is needed prior to using embarcadero mind machine. An OAuth App \u00b6 You also need to create an OAuth application. You can use one application across all of your bot flocks - there is no limit on the number of accounts a single application can control. It is recommended you create this app using a \"bot master\" account, and not using the bot accounts themselves. This will register your embarcadero mind machine bot flock application with Github, and give you credentials (one token and one secret token) that will allow you to connect to Github's API as the mind machine application that you are about to build. When you register your application you will get a token and a secret token. These are provided to the Keymaker. (See boring mind machine .)","title":"Installing emm"},{"location":"installing/#installing-embarcadero-mind-machine","text":"To install embarcadero mind machine manually, use the normal setup.py procedure: git clone https://github.com/rainbow-mind-machine/embarcadero-mind-machine.git cd embarcadero-mind-machine python setup.py build python setup.py install To install embarcadero mind machine with pip: pip install embarcaderomindmachine","title":"Installing embarcadero mind machine"},{"location":"installing/#required-packages","text":"If you need a list of required packages, see requirements.txt . These packages will be installed using either of the above installation methods.","title":"Required Packages"},{"location":"installing/#what-you-need-to-run-a-bot-flock","text":"You will need a few additional things before you can get a bot flock up and running with embarcadero mind machine.","title":"What You Need to Run a Bot Flock"},{"location":"installing/#a-bot-idea","text":"You will need to decide on the behaviors you want the bot to have, so you know how to structure the bot repository, what data to include, and how to extend Sheep and Shepherd. You will be defining how the Sheep (one sheep = one bot) will populate their tweet queues. This may be a simple action (get an item from a list owned by the Sheep), or it may be a complicated one (make a URL request to get live data, query a database, call an API, etc.). See example_flocks/ .","title":"A Bot Idea"},{"location":"installing/#bot-master-account","text":"It's good practice to create the OAuth application you'll be using to run your bot flock under a bot master account. Like your OAuth application, the bot master account can be used to run as many bot flocks as you would like, so you don't need to make it flock-specific. This account is also (obviously) not itself a bot, so you can use your personal twitter account as the bot master account.","title":"Bot Master Account"},{"location":"installing/#bot-accounts","text":"embarcadero mind machine handles everything but the creation of bot accounts. You must already have created a user account for each bot. No customization of the bot accounts is needed prior to using embarcadero mind machine.","title":"Bot Accounts"},{"location":"installing/#an-oauth-app","text":"You also need to create an OAuth application. You can use one application across all of your bot flocks - there is no limit on the number of accounts a single application can control. It is recommended you create this app using a \"bot master\" account, and not using the bot accounts themselves. This will register your embarcadero mind machine bot flock application with Github, and give you credentials (one token and one secret token) that will allow you to connect to Github's API as the mind machine application that you are about to build. When you register your application you will get a token and a secret token. These are provided to the Keymaker. (See boring mind machine .)","title":"An OAuth App"},{"location":"quickstart/","text":"Quick Start \u00b6 Let's walk through a quick example to illustrate how embarcadero mind machine (emm) works. We only have 3 objects we need to understand: The Keymaker (makes/manages keys and authenticates with Twitter) The Shepherd (runs the flock; one shepherd = one bot flock) The Sheep (runs a bot, and defines bot's behavior; one sheep = one bot) Keymaker: Authentication Step \u00b6 Also see the Keymaker page. The first step in embarcadero mind machine is to run the Keymaker to give the application permission to tweet on behalf of each of our bot users. This generates keys that the embarcadero mind machine application requires to run a bot flock. The actual Keymaker objects for each service are defined in the boring mind machine library. The usage is covered here. The Keymaker takes a set of items as an input, and creates one key for each item. A set of items might be a Python list with integers, or a folder full of text files, or a set of URLs, or just plain old string labels. The keys are what allow our application to tweet using a bot account. We call make_a_key() on each item to create each key. The Keymaker requires that we specify a name parameter to name the bot and a json parameter to specify the location of the key. Also note, this requires that your Twitter app's consumer secret and consumer token be set in apikeys.py . In the example below, the \"items\" are strings containing the bot name. This uses credentials in apikeys.py and outputs key files at keys/key1.json and keys/key2.json . import embarcaderomindmachine as rmm import subprocess subprocess . call ([ 'mkdir' , '-p' , 'keys/' ]) k = rmm . GithubKeymaker () k . set_api_keys_env () # Create some keys k . make_key ({ 'name' : 'red bot' , # This is the bot label (arbitrary) 'json' : 'keys/red_key.json' # This is the key file }) k . make_key ({ 'name' : 'blue bot' , 'json' : 'keys/key2.json' }) When this script is run, the Keymaker will go through a series of interactive steps to create keys from each item. A Shepherd to Run the Bot Flock \u00b6 Also see the Shepherd page. Once that is done, make a Shepherd for the bot flock, and point it to the keys the Keymaker created in the keys/ directory: import embarcaderomindmachine as rmm # make the Shepherd sh = rmm . GiihubShepherd ( \"keys/\" ) # Perform action in serial sh . perform_serial_action ( 'change_avatar' ) # Perform action in parallel sh . perform_serial_action ( 'issue_argument' ) Customizing Sheep \u00b6 Also see the Sheep page. We didn't specify what kind of Sheep we want the Shepherd to create, so the Shepherd uses the default Sheep class. To change the behavior of your bot, you can use built-in Sheep types or you can extend the Sheep class to define custom behaviors. More Examples \u00b6 See the examples/ directory.","title":"Quick Start"},{"location":"quickstart/#quick-start","text":"Let's walk through a quick example to illustrate how embarcadero mind machine (emm) works. We only have 3 objects we need to understand: The Keymaker (makes/manages keys and authenticates with Twitter) The Shepherd (runs the flock; one shepherd = one bot flock) The Sheep (runs a bot, and defines bot's behavior; one sheep = one bot)","title":"Quick Start"},{"location":"quickstart/#keymaker-authentication-step","text":"Also see the Keymaker page. The first step in embarcadero mind machine is to run the Keymaker to give the application permission to tweet on behalf of each of our bot users. This generates keys that the embarcadero mind machine application requires to run a bot flock. The actual Keymaker objects for each service are defined in the boring mind machine library. The usage is covered here. The Keymaker takes a set of items as an input, and creates one key for each item. A set of items might be a Python list with integers, or a folder full of text files, or a set of URLs, or just plain old string labels. The keys are what allow our application to tweet using a bot account. We call make_a_key() on each item to create each key. The Keymaker requires that we specify a name parameter to name the bot and a json parameter to specify the location of the key. Also note, this requires that your Twitter app's consumer secret and consumer token be set in apikeys.py . In the example below, the \"items\" are strings containing the bot name. This uses credentials in apikeys.py and outputs key files at keys/key1.json and keys/key2.json . import embarcaderomindmachine as rmm import subprocess subprocess . call ([ 'mkdir' , '-p' , 'keys/' ]) k = rmm . GithubKeymaker () k . set_api_keys_env () # Create some keys k . make_key ({ 'name' : 'red bot' , # This is the bot label (arbitrary) 'json' : 'keys/red_key.json' # This is the key file }) k . make_key ({ 'name' : 'blue bot' , 'json' : 'keys/key2.json' }) When this script is run, the Keymaker will go through a series of interactive steps to create keys from each item.","title":"Keymaker: Authentication Step"},{"location":"quickstart/#a-shepherd-to-run-the-bot-flock","text":"Also see the Shepherd page. Once that is done, make a Shepherd for the bot flock, and point it to the keys the Keymaker created in the keys/ directory: import embarcaderomindmachine as rmm # make the Shepherd sh = rmm . GiihubShepherd ( \"keys/\" ) # Perform action in serial sh . perform_serial_action ( 'change_avatar' ) # Perform action in parallel sh . perform_serial_action ( 'issue_argument' )","title":"A Shepherd to Run the Bot Flock"},{"location":"quickstart/#customizing-sheep","text":"Also see the Sheep page. We didn't specify what kind of Sheep we want the Shepherd to create, so the Shepherd uses the default Sheep class. To change the behavior of your bot, you can use built-in Sheep types or you can extend the Sheep class to define custom behaviors.","title":"Customizing Sheep"},{"location":"quickstart/#more-examples","text":"See the examples/ directory.","title":"More Examples"},{"location":"mind-machine-docs/about/","text":"Mind Machine Framework \u00b6 The mind machine framework is designed to be a simple, extensible framework for developing bots. How is it simple? \u00b6 The mind machine concept is simple because there are only three components: Keymaker Sheep Shepherd These are the three types of objects that you deal with in any given mind machine (and you should not have to deal with the Keymaker much). How is it extensible? \u00b6 The concept of \"extensible\" refers specifically to the use of inheritance and extended classes. We want to keep things as simple as possible, but also build functionality up into complicated bots. Using base classes and extending one bit at a time helps us accomplish that. How is it POOP-y? \u00b6 The mind machine libraries are a great illustration of Python Object-Oriented Programming (POOP) in action. These are very POOP-y libraries, in that they use classes to combine minimal functionality into classes. We will point out the many examples of POOP-y behavior when we see them in a particular mind machine example.","title":"About Mind Machine Framework"},{"location":"mind-machine-docs/about/#mind-machine-framework","text":"The mind machine framework is designed to be a simple, extensible framework for developing bots.","title":"Mind Machine Framework"},{"location":"mind-machine-docs/about/#how-is-it-simple","text":"The mind machine concept is simple because there are only three components: Keymaker Sheep Shepherd These are the three types of objects that you deal with in any given mind machine (and you should not have to deal with the Keymaker much).","title":"How is it simple?"},{"location":"mind-machine-docs/about/#how-is-it-extensible","text":"The concept of \"extensible\" refers specifically to the use of inheritance and extended classes. We want to keep things as simple as possible, but also build functionality up into complicated bots. Using base classes and extending one bit at a time helps us accomplish that.","title":"How is it extensible?"},{"location":"mind-machine-docs/about/#how-is-it-poop-y","text":"The mind machine libraries are a great illustration of Python Object-Oriented Programming (POOP) in action. These are very POOP-y libraries, in that they use classes to combine minimal functionality into classes. We will point out the many examples of POOP-y behavior when we see them in a particular mind machine example.","title":"How is it POOP-y?"},{"location":"mind-machine-docs/credits/","text":"Credits \u00b6 Most of the magic in rainbow mind machine happens via the excellent bear/python-twitter library. All of the amazing artwork is available via the Creative Commons License compliments of user @russloar on flickr. Photographs in the embarcadero mind machine library are compliments of @charlesreid1 . Comic of Calvin's Dad in the boring mind machine library is compliments of Bill Watterson , author of Calvin and Hobbes . Also see the Calvin and Hobbes wiki .","title":"Credits"},{"location":"mind-machine-docs/credits/#credits","text":"Most of the magic in rainbow mind machine happens via the excellent bear/python-twitter library. All of the amazing artwork is available via the Creative Commons License compliments of user @russloar on flickr. Photographs in the embarcadero mind machine library are compliments of @charlesreid1 . Comic of Calvin's Dad in the boring mind machine library is compliments of Bill Watterson , author of Calvin and Hobbes . Also see the Calvin and Hobbes wiki .","title":"Credits"},{"location":"mind-machine-docs/dev/","text":"Developer Notes \u00b6 Makefiles \u00b6 The Makefile in each mind machine repository provides rules to help you perform common tasks. There are three types of tasks: Makefile rules run after the first clone of a brand-new mind machine repo Makefile rules run after a fresh clone of an existing mind machine repo Makefile rules for testing, creating, deploying The Prime Number Version System \u00b6 Crash course in the prime number version system: Branches: master - contains stable, tagged releases. Each release is a unique prime number, occurring in ascending order. dev - development branch. All work happens here. feature - feature branch. Feature branches are created from the dev branch, and commits from these feature branches are merged back into the dev branch before they are ultimately added to a mind machine release. prerelease/vP - branch preparing a release of version P (updating docs, fixing tests, etc). release/vP - branch with releases of version P. Workflow: Start from a stable version on master Create branch dev from master (or pull from master into dev if it already exists) Create branch feature from dev (feature branch contains all work on a particular feature) When ready, merge changes from feature into dev Once dev branch is ready for a release, create a pre-release branch prerelease/vP Fill out pre-release checklist and test checklist (see below) Cut new release on branch release/vP Tag, push to Github, upload to PyPI, add to Dockerhub Release Process \u00b6 The following checklists help in preparing for releases on PyPI or Dockerhub. Releases happen in a two-step process. Pre-Release Checklist \u00b6 A new release happens when the code is stable. The first step in the release process is to create a pre-release branch, where the code base can be modified but the modifications will generally be specific to the version being released. (For example, updating the version number in setup.py ). Pre-release checklist: setup.py tasks: Does setup.py build work without errors? Does setup.py install work without errors? Has the description in setup.py been defined and updated? Have the requirements in setup.py been changed, and do they match the requirements in requirements.txt ? Does this mind machine properly depend on the correct, new version of boring mind machine? Has the version number in setup.py been bumped? Documentation tasks: Has the version number in the documentation (shield on docs/index.md page) been updated? Has Readme ben updated/quickstart instructions tested? Git tasks: Is the submodule using HTTPS? (should not use SSH) Have submodules been updated? git submodule foreach git checkout master; git submodule foreach git pull origin master Does this release include any large files? Are they necessary? Can they be slimmed? Docker tasks: Is the Dockerfile cloning the repo from the correct URL? Can a simple (non-mind-machine) python-alpine Dockerfile install the requirements in requirements.txt ? Tests Checklist \u00b6 The second step is to go through the build, run, and test process. Test checklist: Nose tests Does python setup.py test pass? Docker Can the Docker container be created using the shell script? Does python setup.py test pass inside the container? Documentation Does mkdocs build work? Is updated documentation ready to deploy? Create Release Branch \u00b6 Once the release checklist has been completed and everything is passing tests, the prerelease branch should be made into a release branch. This can be done by renaming the prerelease branch, git branch -m prereleases/vXYZ releases/vXYZ or by creating a new releases branch from the prerelases branch: git branch releases/vXYZ git checkout releases/vXYZ Create Tags \u00b6 After the new releases branch is created, a tag should be created that points to the head commit of the release branch. Create a git tag: git tag vXYZ.0 git push origin vXYZ.0 This will add the new version tag to the \"Releases\" page of the package's Github repository Testing Release from Github \u00b6 Test downloading anad installing the new release from Github: wget https://github.com/rainbow-mind-machine/boring-mind-machine/archive/vXYZ.zip unzip vXYZ.zip ...see installation instructions... Set Up PyPI Account \u00b6 Ensure you have a PyPI account before you upload the new release to PyPI and make it pip-installable. To set up an account on PyPI: python setup.py register add the following to ~/.pypirc: ~/.pypirc : [distutils] index-servers = pypi [pypi] username:charlesreid1 password:YOURPASSWORDHERE Upload Release to PyPI \u00b6 PyPI = Python Package Index (where pip looks by default) When ready, the steps to release on PyPI are as follows: Create a distribution locally Upload the distribution to PyPI Test the new release in a virtual environment Start by making a distribution package bundle: $ python setup.py sdist Upload it to pypi: $ python setup.py sdist upload Test it out with virutalenv: $ virtualenv vp && cd vp $ source bin/activate $ bin/pip install boringmindmachine Set Up Dockerhub Account \u00b6 Before updating the latest container image available for the project on Dockerhub, you should create a Dockerhub account. There is no command line interface needed, as Dockerhub builds are configured via the web interface and webhooks. Update Container Image on Dockerhub \u00b6 To update the latest container image available for the project on Dockerhub, add the new version's tag to the list of versions that Dockerhub will build. You can also configure webhooks so that new images are built whenever a particular branch is updated, but tagged versions won't change much so they only require building once. Useful Links \u00b6 Guide to packaging a minimal Python application: http://python-packaging.readthedocs.io/en/latest/minimal.html Uploading distributions to PyPI: https://packaging.python.org/guides/migrating-to-pypi-org/#uploading Example scripts and guide: https://gist.github.com/gboeing/dcfaf5e13fad16fc500717a3a324ec17","title":"Developer Notes"},{"location":"mind-machine-docs/dev/#developer-notes","text":"","title":"Developer Notes"},{"location":"mind-machine-docs/dev/#makefiles","text":"The Makefile in each mind machine repository provides rules to help you perform common tasks. There are three types of tasks: Makefile rules run after the first clone of a brand-new mind machine repo Makefile rules run after a fresh clone of an existing mind machine repo Makefile rules for testing, creating, deploying","title":"Makefiles"},{"location":"mind-machine-docs/dev/#the-prime-number-version-system","text":"Crash course in the prime number version system: Branches: master - contains stable, tagged releases. Each release is a unique prime number, occurring in ascending order. dev - development branch. All work happens here. feature - feature branch. Feature branches are created from the dev branch, and commits from these feature branches are merged back into the dev branch before they are ultimately added to a mind machine release. prerelease/vP - branch preparing a release of version P (updating docs, fixing tests, etc). release/vP - branch with releases of version P. Workflow: Start from a stable version on master Create branch dev from master (or pull from master into dev if it already exists) Create branch feature from dev (feature branch contains all work on a particular feature) When ready, merge changes from feature into dev Once dev branch is ready for a release, create a pre-release branch prerelease/vP Fill out pre-release checklist and test checklist (see below) Cut new release on branch release/vP Tag, push to Github, upload to PyPI, add to Dockerhub","title":"The Prime Number Version System"},{"location":"mind-machine-docs/dev/#release-process","text":"The following checklists help in preparing for releases on PyPI or Dockerhub. Releases happen in a two-step process.","title":"Release Process"},{"location":"mind-machine-docs/dev/#pre-release-checklist","text":"A new release happens when the code is stable. The first step in the release process is to create a pre-release branch, where the code base can be modified but the modifications will generally be specific to the version being released. (For example, updating the version number in setup.py ). Pre-release checklist: setup.py tasks: Does setup.py build work without errors? Does setup.py install work without errors? Has the description in setup.py been defined and updated? Have the requirements in setup.py been changed, and do they match the requirements in requirements.txt ? Does this mind machine properly depend on the correct, new version of boring mind machine? Has the version number in setup.py been bumped? Documentation tasks: Has the version number in the documentation (shield on docs/index.md page) been updated? Has Readme ben updated/quickstart instructions tested? Git tasks: Is the submodule using HTTPS? (should not use SSH) Have submodules been updated? git submodule foreach git checkout master; git submodule foreach git pull origin master Does this release include any large files? Are they necessary? Can they be slimmed? Docker tasks: Is the Dockerfile cloning the repo from the correct URL? Can a simple (non-mind-machine) python-alpine Dockerfile install the requirements in requirements.txt ?","title":"Pre-Release Checklist"},{"location":"mind-machine-docs/dev/#tests-checklist","text":"The second step is to go through the build, run, and test process. Test checklist: Nose tests Does python setup.py test pass? Docker Can the Docker container be created using the shell script? Does python setup.py test pass inside the container? Documentation Does mkdocs build work? Is updated documentation ready to deploy?","title":"Tests Checklist"},{"location":"mind-machine-docs/dev/#create-release-branch","text":"Once the release checklist has been completed and everything is passing tests, the prerelease branch should be made into a release branch. This can be done by renaming the prerelease branch, git branch -m prereleases/vXYZ releases/vXYZ or by creating a new releases branch from the prerelases branch: git branch releases/vXYZ git checkout releases/vXYZ","title":"Create Release Branch"},{"location":"mind-machine-docs/dev/#create-tags","text":"After the new releases branch is created, a tag should be created that points to the head commit of the release branch. Create a git tag: git tag vXYZ.0 git push origin vXYZ.0 This will add the new version tag to the \"Releases\" page of the package's Github repository","title":"Create Tags"},{"location":"mind-machine-docs/dev/#testing-release-from-github","text":"Test downloading anad installing the new release from Github: wget https://github.com/rainbow-mind-machine/boring-mind-machine/archive/vXYZ.zip unzip vXYZ.zip ...see installation instructions...","title":"Testing Release from Github"},{"location":"mind-machine-docs/dev/#set-up-pypi-account","text":"Ensure you have a PyPI account before you upload the new release to PyPI and make it pip-installable. To set up an account on PyPI: python setup.py register add the following to ~/.pypirc: ~/.pypirc : [distutils] index-servers = pypi [pypi] username:charlesreid1 password:YOURPASSWORDHERE","title":"Set Up PyPI Account"},{"location":"mind-machine-docs/dev/#upload-release-to-pypi","text":"PyPI = Python Package Index (where pip looks by default) When ready, the steps to release on PyPI are as follows: Create a distribution locally Upload the distribution to PyPI Test the new release in a virtual environment Start by making a distribution package bundle: $ python setup.py sdist Upload it to pypi: $ python setup.py sdist upload Test it out with virutalenv: $ virtualenv vp && cd vp $ source bin/activate $ bin/pip install boringmindmachine","title":"Upload Release to PyPI"},{"location":"mind-machine-docs/dev/#set-up-dockerhub-account","text":"Before updating the latest container image available for the project on Dockerhub, you should create a Dockerhub account. There is no command line interface needed, as Dockerhub builds are configured via the web interface and webhooks.","title":"Set Up Dockerhub Account"},{"location":"mind-machine-docs/dev/#update-container-image-on-dockerhub","text":"To update the latest container image available for the project on Dockerhub, add the new version's tag to the list of versions that Dockerhub will build. You can also configure webhooks so that new images are built whenever a particular branch is updated, but tagged versions won't change much so they only require building once.","title":"Update Container Image on Dockerhub"},{"location":"mind-machine-docs/dev/#useful-links","text":"Guide to packaging a minimal Python application: http://python-packaging.readthedocs.io/en/latest/minimal.html Uploading distributions to PyPI: https://packaging.python.org/guides/migrating-to-pypi-org/#uploading Example scripts and guide: https://gist.github.com/gboeing/dcfaf5e13fad16fc500717a3a324ec17","title":"Useful Links"},{"location":"mind-machine-docs/keymaker/","text":"The Keymaker \u00b6 the mind machine keymaker. trust it with your keys. The Keymaker is the object that is used to authenticate with the third party service and generate the bot keys the application needs to do things on behalf of a user account. This document provides a high-level overview of the Keymaker. Using the Keymaker \u00b6 If you don't care about all of this business and just want to know how to use the keymaker, see the boring mind machine documentation . Specifically, see coverage of the BoringOAuthKeymaker class, along with the service-specific Github Keymaker , Google Keymaker , and Twitter Keymaker classes. Background: The Three-Legged OAuth Process \u00b6 In theory, not all Keymakers must do OAuth, but in practice, all Keymakers do OAuth . The Keymaker carries out a one-time authorization step that needs to be done once for each Sheep = bot = account. The Keymaker will be given a set of \"items\" (more on this in a moment), with one item = one Sheep = one bot = one account, etc. The Keymaker iterates through each item and performs the three-legged OAuth process. Here's a summary of the process: The three legs are: the user (the bot account), the third party service (Github/Google/Twitter/other), and the consumer (your mind machine app - specifically, the Keymaker component) The Keymaker will initiate the process by requesting an OAuth URL from the third party (this is how an app asks a user for permission to access their account) Third party will return an OAuth URL to the Keymaker, which will pass it to the user The user will open the URL in their browser, and sign in using a bot account Third party will verify the credentials of the user, and create a temporary token This token is returned to the API application (via callback URL/other mechanism) API application sends the token to the third party, which verifies the token matches Third party gives the API application a new OAuth token. This is the magic token that allows the OAuth application to do things with the bot account. Why the song and dance? The three-legged authentication process is intended to allow API applications to verify a user's identity (i.e., yes this user actually granted permission for the API application to control their account) without having to handle sensitive data like a user's hashed password. It also keeps the third party in control of the process. Keymaker Credentials \u00b6 Keymaker Input: API Keys \u00b6 There are two pieces of information that are required to do things as your API application (independent of any bot accounts): API application key API application secret key These are the two pieces of information that are required to prove to the third party service that you are the actual owner of your application. Each service stores these pieces of information in different ways, and calls them by different names. For example: Client key/client secret key Consumer token/consumer token secret API token/API secret token etc... The boring mind machine library provides a base OAuth Keymaker class called BoringOAuthKeymaker. This class implements the OAuth process in a generic way. The details specific to the third party service are then implemented in child classes (e.g., GithubKeymaker). Keymaker Output: OAuth Keys \u00b6 In general, the Keymaker creates a set of bot account keys corresponding to a set of items. Once the Keymaker and the user go through the three-legged authentication process for one bot account, the Keymaker will create a JSON file with the bot key so that it can be used again in the future. The bot key contains both the API keys for the application, and the OAuth keys for the bot account.","title":"Keymaker"},{"location":"mind-machine-docs/keymaker/#the-keymaker","text":"the mind machine keymaker. trust it with your keys. The Keymaker is the object that is used to authenticate with the third party service and generate the bot keys the application needs to do things on behalf of a user account. This document provides a high-level overview of the Keymaker.","title":"The Keymaker"},{"location":"mind-machine-docs/keymaker/#using-the-keymaker","text":"If you don't care about all of this business and just want to know how to use the keymaker, see the boring mind machine documentation . Specifically, see coverage of the BoringOAuthKeymaker class, along with the service-specific Github Keymaker , Google Keymaker , and Twitter Keymaker classes.","title":"Using the Keymaker"},{"location":"mind-machine-docs/keymaker/#background-the-three-legged-oauth-process","text":"In theory, not all Keymakers must do OAuth, but in practice, all Keymakers do OAuth . The Keymaker carries out a one-time authorization step that needs to be done once for each Sheep = bot = account. The Keymaker will be given a set of \"items\" (more on this in a moment), with one item = one Sheep = one bot = one account, etc. The Keymaker iterates through each item and performs the three-legged OAuth process. Here's a summary of the process: The three legs are: the user (the bot account), the third party service (Github/Google/Twitter/other), and the consumer (your mind machine app - specifically, the Keymaker component) The Keymaker will initiate the process by requesting an OAuth URL from the third party (this is how an app asks a user for permission to access their account) Third party will return an OAuth URL to the Keymaker, which will pass it to the user The user will open the URL in their browser, and sign in using a bot account Third party will verify the credentials of the user, and create a temporary token This token is returned to the API application (via callback URL/other mechanism) API application sends the token to the third party, which verifies the token matches Third party gives the API application a new OAuth token. This is the magic token that allows the OAuth application to do things with the bot account. Why the song and dance? The three-legged authentication process is intended to allow API applications to verify a user's identity (i.e., yes this user actually granted permission for the API application to control their account) without having to handle sensitive data like a user's hashed password. It also keeps the third party in control of the process.","title":"Background: The Three-Legged OAuth Process"},{"location":"mind-machine-docs/keymaker/#keymaker-credentials","text":"","title":"Keymaker Credentials"},{"location":"mind-machine-docs/keymaker/#keymaker-input-api-keys","text":"There are two pieces of information that are required to do things as your API application (independent of any bot accounts): API application key API application secret key These are the two pieces of information that are required to prove to the third party service that you are the actual owner of your application. Each service stores these pieces of information in different ways, and calls them by different names. For example: Client key/client secret key Consumer token/consumer token secret API token/API secret token etc... The boring mind machine library provides a base OAuth Keymaker class called BoringOAuthKeymaker. This class implements the OAuth process in a generic way. The details specific to the third party service are then implemented in child classes (e.g., GithubKeymaker).","title":"Keymaker Input: API Keys"},{"location":"mind-machine-docs/keymaker/#keymaker-output-oauth-keys","text":"In general, the Keymaker creates a set of bot account keys corresponding to a set of items. Once the Keymaker and the user go through the three-legged authentication process for one bot account, the Keymaker will create a JSON file with the bot key so that it can be used again in the future. The bot key contains both the API keys for the application, and the OAuth keys for the bot account.","title":"Keymaker Output: OAuth Keys"},{"location":"mind-machine-docs/sheep/","text":"The Sheep \u00b6 The mind machine sheep. The Sheep is the component of the bot flock that actually performs the actions using the bot accounts. The Shepherd will instruct each Sheep to start performing an action - either in parallel (if it is a \"forever\" action like tweeting) or in serial (if it is a \"one-time\" action, like changing the bot user's profile). Each Sheep uses a bot key (created by the Keymaker and loaded by the Shepherd) to create an API instance in the constructor. Each Sheep then uses that API instance to perform actions. The BoringSheep base class in boring mind machine defines a generic dispatcher method (which turns strings into function calls) to allow Shepherds to call particular actions for each Sheep. Defining Actions \u00b6 To define an action, define a method for that action. (For example, to define a tweet action, make a tweet() method in the Sheep class you are using.) To control how the action works and introduce variation, you can pass extra parameters (in the form of keyword arguments) to the action method, and the Shepherd will pass those along to the Sheep. The general pattern this follows is: set up or point to an API endpoint create or use the API client object to call the API endpoint process the results","title":"Sheep"},{"location":"mind-machine-docs/sheep/#the-sheep","text":"The mind machine sheep. The Sheep is the component of the bot flock that actually performs the actions using the bot accounts. The Shepherd will instruct each Sheep to start performing an action - either in parallel (if it is a \"forever\" action like tweeting) or in serial (if it is a \"one-time\" action, like changing the bot user's profile). Each Sheep uses a bot key (created by the Keymaker and loaded by the Shepherd) to create an API instance in the constructor. Each Sheep then uses that API instance to perform actions. The BoringSheep base class in boring mind machine defines a generic dispatcher method (which turns strings into function calls) to allow Shepherds to call particular actions for each Sheep.","title":"The Sheep"},{"location":"mind-machine-docs/sheep/#defining-actions","text":"To define an action, define a method for that action. (For example, to define a tweet action, make a tweet() method in the Sheep class you are using.) To control how the action works and introduce variation, you can pass extra parameters (in the form of keyword arguments) to the action method, and the Shepherd will pass those along to the Sheep. The general pattern this follows is: set up or point to an API endpoint create or use the API client object to call the API endpoint process the results","title":"Defining Actions"},{"location":"mind-machine-docs/shepherd/","text":"The Shepherd \u00b6 The shepherd's ( pasteur ) power manifests itself, therefore, in a duty, a task to be undertaken, so that - and I think this is also an important characteristic of pastoral power - the form it takes is not first of all the striking display of strength and superiority. Pastoral power initially manifests itself in its zeal, devotion, and endless application. What is the shepherd ( berger )? Is (s)he someone whose strength strikes people's eyes, like the sovereigns or gods, like the Greek gods, who essentially appear in their splendor? Not at all. The shepherd is someone who keeps watch. (S)he \"keeps watch\" in the sense, of course, of keeping an eye out for possible evils, but above all in the sense of vigilance with regard to any possible misfortune. Michel Foucault, Security, Territory, Population: Lectures at the Coll\u00e9ge de France (1977-1978) The mind machine shepherd. credit what is the Shepherd? \u00b6 The Shepherd is a very simple object. The Shepherd is a data container for storing Sheep. when does the Shepherd come in? \u00b6 The first thing a bot flock needs is a set of keys. That's what the Keymaker is for. Once the bot flock keys have been created with the Keymaker, the bot flock is started. To do that, the Shepherd initializes each Sheep with a corresponding JSON key file (created by the Keymaker). how does the Shepherd tend to the Sheep? \u00b6 In general, the Shepherd is a free-range parent, and lets the Sheep go off and do their own thing. Note however, that in the spirit of extensibility, you can extend the Shepherd and Sheep classes to change the nature of your bot flock. (See next section.) when and how do you extend the Shepherd? \u00b6 The Shepherd class determines how much coordination happens among different Sheep in the flock and between the flock and the outside world (the Internet). Let's look at some simple examples of when you would need to extend the Shepherd class, and what modifications would be required. storing custom parameters \u00b6 First, let's mention a feature of the Shepherd that makes adding new parameters to extended versions of the Shepherd class really simple. The Shepherd constructor __init__() includes a **kwargs argument at the end. This will create a dictionary called kwargs with any key-value pairs the user passed in. This is stored in self.params at the end of the constructor: self.params = kwargs This means that if you create a new Shepherd class like CarMechanicShepherd , and you need to pass in (say) a boolean input parameter like uses_metric , you don't have to explicitly modify the constructor to take uses_metric as a parameter; the Shepherd class automatically adds a key uses_metric with a value True||False to a dictionary self.params when you call the constructor like CarMechanicShepherd(uses_metric=False) Okay, back to the regularly scheduled program... webhook bot flock \u00b6 As an example of a bot flock that requires tighter integration between the Shepherd and the Sheep, imagine you want to create a bot fock where the bots can be controlled with webhooks. You would need the Shepherd to act as a central dispatcher and process incoming webhooks to determine which webhook payloads to pass on to which Sheep. But the Sheep also need to be modified to listen for instructions from the Shepherd. To modify the Shepherd class, we would add a method that listens for incoming webhooks, and a method or methods implementing logic about which payloads to pass along to which Sheep (or to call the appropriate functions when webhooks trigger flock-wide actions). To modify the Sheep class, we would add a listen() method that would run forever - ideally in parallel with other run-forever methods. two bots per key flock \u00b6 Suppose we wanted to build an argument bot flock. This bot flock would consist of pairs of Sheep that use Queneau generation to create dialogue, and that argue back and forth forever with each other. This bot flock modifies the way that our Sheep coordinate with each other, which is an indication we should change the Shepherd class. The Sheep bots we will use will work identically to a normal Queneau Sheep bot. Each bot generates dialogue from a single speaker, and tweets it in response to another bot tweeting. While we could extend the Sheep class to control the dialogue, it would be easier to use the inner/outer loop structure that the QueneauSheep class already has. That way, the Sheep do not require any extending. The Shepherd class needs to be modified by changing the way it instantiates bots from keys. Instead of creating one bot per key, it should create two bots per keys. (Note that the user will need to provide relevant details in the key or config dictionaries. For example, name and handle of both bot sides, inner/outer loop timing, etc.) The -setup_keys() method will not change, because we want to maintain the consistency of one key file corresponding to one bot corresponding to one Twitter account. The _setup_sheep() method would be modified from its current arrangement (pseudocode): current _setup_sheep() method: for json in list-of-all-json-files: create new sheep from json add new sheep to flock to something more like (pseudocode): new _setup_sheep() method: for (bot1, bot2) in list-of-all-bot-pairs: get key1 from keys create bot1 from key1 get key2 from keys create bot2 from key2 link bot1 and bot2 add bot1 and bot2 to flock In this case, we want to have two Queneau Sheep that work almost exactly the same as normal Queneau Sheep, with perhaps a slight modification to make sure that each bot generates dialogue from a single speaker corresponding to their party in the argument.","title":"Shepherd"},{"location":"mind-machine-docs/shepherd/#the-shepherd","text":"The shepherd's ( pasteur ) power manifests itself, therefore, in a duty, a task to be undertaken, so that - and I think this is also an important characteristic of pastoral power - the form it takes is not first of all the striking display of strength and superiority. Pastoral power initially manifests itself in its zeal, devotion, and endless application. What is the shepherd ( berger )? Is (s)he someone whose strength strikes people's eyes, like the sovereigns or gods, like the Greek gods, who essentially appear in their splendor? Not at all. The shepherd is someone who keeps watch. (S)he \"keeps watch\" in the sense, of course, of keeping an eye out for possible evils, but above all in the sense of vigilance with regard to any possible misfortune. Michel Foucault, Security, Territory, Population: Lectures at the Coll\u00e9ge de France (1977-1978) The mind machine shepherd. credit","title":"The Shepherd"},{"location":"mind-machine-docs/shepherd/#what-is-the-shepherd","text":"The Shepherd is a very simple object. The Shepherd is a data container for storing Sheep.","title":"what is the Shepherd?"},{"location":"mind-machine-docs/shepherd/#when-does-the-shepherd-come-in","text":"The first thing a bot flock needs is a set of keys. That's what the Keymaker is for. Once the bot flock keys have been created with the Keymaker, the bot flock is started. To do that, the Shepherd initializes each Sheep with a corresponding JSON key file (created by the Keymaker).","title":"when does the Shepherd come in?"},{"location":"mind-machine-docs/shepherd/#how-does-the-shepherd-tend-to-the-sheep","text":"In general, the Shepherd is a free-range parent, and lets the Sheep go off and do their own thing. Note however, that in the spirit of extensibility, you can extend the Shepherd and Sheep classes to change the nature of your bot flock. (See next section.)","title":"how does the Shepherd tend to the Sheep?"},{"location":"mind-machine-docs/shepherd/#when-and-how-do-you-extend-the-shepherd","text":"The Shepherd class determines how much coordination happens among different Sheep in the flock and between the flock and the outside world (the Internet). Let's look at some simple examples of when you would need to extend the Shepherd class, and what modifications would be required.","title":"when and how do you extend the Shepherd?"},{"location":"mind-machine-docs/shepherd/#storing-custom-parameters","text":"First, let's mention a feature of the Shepherd that makes adding new parameters to extended versions of the Shepherd class really simple. The Shepherd constructor __init__() includes a **kwargs argument at the end. This will create a dictionary called kwargs with any key-value pairs the user passed in. This is stored in self.params at the end of the constructor: self.params = kwargs This means that if you create a new Shepherd class like CarMechanicShepherd , and you need to pass in (say) a boolean input parameter like uses_metric , you don't have to explicitly modify the constructor to take uses_metric as a parameter; the Shepherd class automatically adds a key uses_metric with a value True||False to a dictionary self.params when you call the constructor like CarMechanicShepherd(uses_metric=False) Okay, back to the regularly scheduled program...","title":"storing custom parameters"},{"location":"mind-machine-docs/shepherd/#webhook-bot-flock","text":"As an example of a bot flock that requires tighter integration between the Shepherd and the Sheep, imagine you want to create a bot fock where the bots can be controlled with webhooks. You would need the Shepherd to act as a central dispatcher and process incoming webhooks to determine which webhook payloads to pass on to which Sheep. But the Sheep also need to be modified to listen for instructions from the Shepherd. To modify the Shepherd class, we would add a method that listens for incoming webhooks, and a method or methods implementing logic about which payloads to pass along to which Sheep (or to call the appropriate functions when webhooks trigger flock-wide actions). To modify the Sheep class, we would add a listen() method that would run forever - ideally in parallel with other run-forever methods.","title":"webhook bot flock"},{"location":"mind-machine-docs/shepherd/#two-bots-per-key-flock","text":"Suppose we wanted to build an argument bot flock. This bot flock would consist of pairs of Sheep that use Queneau generation to create dialogue, and that argue back and forth forever with each other. This bot flock modifies the way that our Sheep coordinate with each other, which is an indication we should change the Shepherd class. The Sheep bots we will use will work identically to a normal Queneau Sheep bot. Each bot generates dialogue from a single speaker, and tweets it in response to another bot tweeting. While we could extend the Sheep class to control the dialogue, it would be easier to use the inner/outer loop structure that the QueneauSheep class already has. That way, the Sheep do not require any extending. The Shepherd class needs to be modified by changing the way it instantiates bots from keys. Instead of creating one bot per key, it should create two bots per keys. (Note that the user will need to provide relevant details in the key or config dictionaries. For example, name and handle of both bot sides, inner/outer loop timing, etc.) The -setup_keys() method will not change, because we want to maintain the consistency of one key file corresponding to one bot corresponding to one Twitter account. The _setup_sheep() method would be modified from its current arrangement (pseudocode): current _setup_sheep() method: for json in list-of-all-json-files: create new sheep from json add new sheep to flock to something more like (pseudocode): new _setup_sheep() method: for (bot1, bot2) in list-of-all-bot-pairs: get key1 from keys create bot1 from key1 get key2 from keys create bot2 from key2 link bot1 and bot2 add bot1 and bot2 to flock In this case, we want to have two Queneau Sheep that work almost exactly the same as normal Queneau Sheep, with perhaps a slight modification to make sure that each bot generates dialogue from a single speaker corresponding to their party in the argument.","title":"two bots per key flock"}]}